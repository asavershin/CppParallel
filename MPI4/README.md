# Ахтунг
Результаты выписаны для 10 процессов. Можно поиграться и получить разные результаты, на разном количестве.   
Я лишь привёл тот вариант, который даёт наилучший результат для 2000x2000.   
Результат без параллеллелизма я запускал на этом же коде с флагом -np 1.   
Я решил это сделать, так как в этой реализации я использую статические массивы, вместо vector.  

# Параллельно
Размер сетки: 10x10 Время выполнения: 0.000560323 секунд
Размер сетки: 100x100 Время выполнения: 0.00387303 секунд
Размер сетки: 1000x1000 Время выполнения: 1.62075 секунд
Размер сетки: 2000x2000 Время выполнения: 15.5414 секунд

# Без параллелизма
Размер сетки: 10x10 Время выполнения: 7.2963e-05 секунд
Размер сетки: 100x100 Время выполнения: 0.00781805 секунд
Размер сетки: 1000x1000 Время выполнения: 10.2933 секунд
Размер сетки: 2000x2000 Время выполнения: 86.887 секунд 

# Вывод
В этой задаче MPI показал, результаты лучше. Возможно это связано с использованием другой структуры данных для хранения.   
Хотя, опять же, замедлиться работа в сравнении с openMP должна была из-за передачи ресурсов между процессами, но видимо это чем-то   нивелировалось. В этот раз MPI был лучше последовательного алгоритма, что, скорее всего, говорит о том, что сам алгоритм перемножения   сильно тяжелее, чем передача ресурсов между процессами, в отличие от прошлых задач.  